# from sklearn.externals import joblib
from keras.preprocessing.text import Tokenizer
import fasttext

content = ['改变', '我', '如何', '起手']
